{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement :\n",
    "Building  an  Interpreter  in  Python  language  that  does  divide.  Work  with  tokens,  lexical analyzer, and expressions that divide integers from integers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps involved in making an interpreter :\n",
    ".1) Take input from the user in form of .txt file <br>\n",
    ".2) Lexical analysis on the file to remove '\\t' and whitespaces.<br>\n",
    ".3) Store variables encountered in symbol table <br>\n",
    ".4) Evaluate expressions by parsing through token streams how we do for infix expressions.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .1) Code to accept .txt file as input\n",
    "here 'lines' is a list containing all the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a = 23.3\\n', 'b = a/5\\n', 'c = d/2']\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .2) Lexical analysis on the file to remove '\\t' and whitespaces.\n",
    "here we do lexical analysis on each line in 'lines'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our lexer function which tokenizes each line\n",
    "\n",
    "def isDigit(a):\n",
    "    \"\"\"\n",
    "    checks whether a character is digit or not.\n",
    "    input : (char) accepts a character\n",
    "    output : (bool) returns true if it is a digit \n",
    "    \"\"\"\n",
    "    if a>='0' and a<='9':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isLetter(a):\n",
    "    \"\"\"\n",
    "    checks whether a character is alphabet or not.\n",
    "    input : (char) accepts a character\n",
    "    output : (bool) returns true if it is a alphabet \n",
    "    \"\"\"\n",
    "    if (a>='a' and a<='z') or (a>='A' and a<='Z') or (a=='_'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# We define some DFAs here\n",
    "\n",
    "def DFA_identifier(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is an identifier or not\n",
    "    input : (string) s\n",
    "    output : (bool) returns true if s is an identifier.\n",
    "    \"\"\"\n",
    "    if isLetter(s[0]):\n",
    "        for i in range(1,len(s)):\n",
    "            if isLetter(s[i]) or isDigit(s[i]):\n",
    "                pass\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def DFA_num(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is an number or not\n",
    "    input : (string) s\n",
    "    output : (bool) returns true if s is an number.\n",
    "    \"\"\"\n",
    "    dec=False\n",
    "    if isDigit(s[0]):\n",
    "        for i in range(1,len(s)):\n",
    "            if isDigit(s[i]) :\n",
    "                pass\n",
    "            elif s[i]=='.' and dec==False:\n",
    "                dec=True\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def DFA_equal(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is '='\n",
    "    input : (string) s\n",
    "    output : returns if string is equal to '='\n",
    "    \"\"\"\n",
    "    return s=='='\n",
    "\n",
    "def DFA_divide(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is '/'\n",
    "    input : (string) s\n",
    "    output : returns if string is equal to '/'\n",
    "    \"\"\"\n",
    "    return s=='/'\n",
    "\n",
    "def DFA_lparen(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is '('\n",
    "    input : (string) s\n",
    "    output : returns if string is equal to '('\n",
    "    \"\"\"\n",
    "    return s=='('\n",
    "\n",
    "def DFA_rparen(s):\n",
    "    \"\"\"\n",
    "    DFA to check if a string is ')'\n",
    "    input : (string) s\n",
    "    output : returns if string is equal to ')'\n",
    "    \"\"\"\n",
    "    return s==')'\n",
    "\n",
    "# function checks for a character in a list of characters\n",
    "\n",
    "def search(c):\n",
    "    \"\"\"\n",
    "    checks if char c is present in list of characters\n",
    "    input : (char) char to be checked\n",
    "    output : (bool) returns true if present\n",
    "    \"\"\"\n",
    "    delim = ['/','=','(',')',' ']\n",
    "    for i in delim:\n",
    "        if c==i:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(s):\n",
    "    \"\"\"\n",
    "    returns the token type of the string.\n",
    "    input : (string) accepts a string and returns token type.\n",
    "    output : (string) returns the token type. \n",
    "    \"\"\"\n",
    "    \n",
    "    if DFA_identifier(s):\n",
    "        return 'IDENT'\n",
    "    \n",
    "    elif DFA_num(s):\n",
    "        return 'NUM'\n",
    "    \n",
    "    elif DFA_equal(s):\n",
    "        return 'EQ'\n",
    "    \n",
    "    elif DFA_divide(s):\n",
    "        return 'DIV'\n",
    "    \n",
    "    elif DFA_lparen(s):\n",
    "        return 'LPAREN'\n",
    "    \n",
    "    elif DFA_rparen(s):\n",
    "        return 'RPAREN'\n",
    "    \n",
    "    return 'none'\n",
    "\n",
    "def Lexer(s):\n",
    "    \"\"\"\n",
    "    converts a line of code into stream of tokens.\n",
    "    input : (string) accepts a line as string.\n",
    "    output : (list of string) returns the stream of tokens. \n",
    "    \"\"\"\n",
    "    lexeme = []\n",
    "    tokens = []\n",
    "    \n",
    "    ptr = 0\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        if search(s[i]):\n",
    "            if s[ptr:i] != '':\n",
    "                lexeme.append(s[ptr:i])\n",
    "            if s[i]!=' ':\n",
    "                lexeme.append(s[i])\n",
    "            ptr = i+1\n",
    "\n",
    "    if s[ptr:] != '':\n",
    "        lexeme.append(s[ptr:])\n",
    "    \n",
    "    for i in lexeme:\n",
    "        tokens.append(token(i))\n",
    "    \n",
    "    return (tokens,lexeme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['IDENT', 'EQ', 'NUM'], ['a', '=', '23.3']), (['IDENT', 'EQ', 'IDENT', 'DIV', 'NUM'], ['b', '=', 'a', '/', '5']), (['IDENT', 'EQ', 'IDENT', 'DIV', 'NUM'], ['c', '=', 'd', '/', '2'])]\n"
     ]
    }
   ],
   "source": [
    "# first we remove '\\n' from end of each line if it is present\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    if lines[i][-1] == '\\n':\n",
    "        lines[i] = lines[i][:-1]\n",
    "\n",
    "# now we tokenize our lines of code\n",
    "\n",
    "list_tokens = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    list_tokens.append(Lexer(lines[i]))\n",
    "        \n",
    "print(list_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute line by line and store variables in symbol table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_paren(lexeme, tokens, sym_tab):\n",
    "    \"\"\"\n",
    "    computes expressions such as 1/((2/2)/3)\n",
    "    Here, we will use the method we use to evaluate infix expressions.\n",
    "    input : \n",
    "        (list of string) lexeme is the list of lexemes.\n",
    "        (list of string) tokens is the list of tokens.\n",
    "        (dict) sym_tab is the dictionary having the symbol table of our past variables.\n",
    "    output : \n",
    "        (float) f is the float value we return after entire computation.\n",
    "    \"\"\"\n",
    "    operand = []\n",
    "    operator = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i]=='NUM':\n",
    "            operand.append(float(lexeme[i]))\n",
    "        elif tokens[i]=='IDENT':\n",
    "            if lexeme[i] in sym_tab:\n",
    "                operand.append(sym_tab[lexeme[i]])\n",
    "            else:\n",
    "                return 'Error : Identifier '+str(lexeme[i])+' not declared.'\n",
    "        elif tokens[i]=='LPAREN':\n",
    "            operator.append('LPAREN')\n",
    "        elif tokens[i]=='DIV':\n",
    "            if len(operator)==0:\n",
    "                operator.append('DIV')\n",
    "            else:\n",
    "                try:\n",
    "                    oprtr_top = operator.pop()\n",
    "                    if oprtr_top=='DIV':\n",
    "                        oprnd_top_1 = operand.pop()\n",
    "                        oprnd_top_2 = operand.pop()\n",
    "                        if oprnd_top_1==0:\n",
    "                            return 'Error : Cannot divide by zero.'\n",
    "                        operand.append(oprnd_top_2/oprnd_top_1)\n",
    "                        operator.append(tokens[i])\n",
    "                    elif oprtr_top=='LPAREN':\n",
    "                        operator.append(oprtr_top)\n",
    "                        operator.append(tokens[i])\n",
    "                    else:\n",
    "                        return 'Error : Invalid expression.'\n",
    "                except:\n",
    "                    return 'Error : Invalid expression.'\n",
    "        elif tokens[i]=='RPAREN':\n",
    "            try:\n",
    "                oprtr_top = operator.pop()\n",
    "                while oprtr_top!='LPAREN':\n",
    "                    oprnd_top_1 = operand.pop()\n",
    "                    oprnd_top_2 = operand.pop()\n",
    "                    if oprnd_top_1==0:\n",
    "                        return 'Error : Cannot divide by zero.'\n",
    "                    if oprtr_top=='DIV':\n",
    "                        operand.append(oprnd_top_2/oprnd_top_1)\n",
    "                    else:\n",
    "                        return 'Error : Invalid operation.'\n",
    "                    oprtr_top = operator.pop()\n",
    "            except:\n",
    "                return 'Error : Invalid expression.'\n",
    "        else:\n",
    "            return 'Error : '+str(lexeme[i])+' not a valid token.'\n",
    "        \n",
    "    while len(operator)!=0:\n",
    "        try : \n",
    "            oprtr_top = operator.pop()\n",
    "            oprnd_top_1 = operand.pop()\n",
    "            oprnd_top_2 = operand.pop()\n",
    "            if oprnd_top_1==0:\n",
    "                return 'Error : Cannot divide by zero.'\n",
    "            operand.append(oprnd_top_2/oprnd_top_1)\n",
    "        except:\n",
    "            return 'Error : Invalid expression.'\n",
    "    \n",
    "    if len(operand)==1:\n",
    "        return operand.pop()\n",
    "    return 'Error : Invalid expression.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3\n",
      "4.66\n",
      "Error in line  3 :  Error : Identifier d not declared.\n",
      "{'a': 23.3, 'b': 4.66}\n"
     ]
    }
   ],
   "source": [
    "sym_tab = {}\n",
    "\n",
    "f = open(\"output.txt\", \"w\")\n",
    "\n",
    "for i in range(len(list_tokens)):\n",
    "    try:\n",
    "        if list_tokens[i][0][1] == 'EQ':\n",
    "            if list_tokens[i][0][0]=='IDENT':\n",
    "                var = comp_paren(list_tokens[i][1][2:],list_tokens[i][0][2:],sym_tab)\n",
    "                if type(var) == str:\n",
    "                    print('Error in line ',i+1,': ',var)\n",
    "                    f.write('Error in line '+str(i+1)+': '+str(var)+'\\n')\n",
    "                else:\n",
    "                    sym_tab[list_tokens[i][1][0]] = var\n",
    "                    print(var)\n",
    "                    f.write(str(var)+'\\n')\n",
    "            else:\n",
    "                print('Error in line '+str(i+1)+': Error :',list_tokens[i][1][0],' not a valid identifier.')\n",
    "                f.write('Error in line '+str(i+1)+': Error :'+str(list_tokens[i][1][0])+' not a valid identifier.\\n')\n",
    "        else:\n",
    "            var = comp_paren(list_tokens[i][1],list_tokens[i][0],sym_tab)\n",
    "            if type(var) == str:\n",
    "                print('Error in line ',i+1,' : ',var)\n",
    "                f.write('Error in line '+str(i+1)+': '+str(var)+'\\n')\n",
    "            else:\n",
    "                print(var)\n",
    "                f.write(str(var)+'\\n')\n",
    "    except:\n",
    "        print('Error : Invalid code.')\n",
    "        f.write('Error in line '+str(i+1)+': Error : Invalid code.\\n')\n",
    "        \n",
    "print(sym_tab)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
